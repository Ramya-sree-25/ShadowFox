# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from textblob import TextBlob
import nltk
from wordcloud import WordCloud
import re

# Download VADER lexicon
nltk.download('vader_lexicon')

# Load the dataset
file_path = 'X data.csv'
df = pd.read_csv(file_path)

# Check for missing values
print(df.isnull().sum())

# Data Cleaning: Dropping rows with missing values in important columns (e.g., text or date columns)
df.dropna(subset=['clean_text'], inplace=True)  # Replace 'text_column_name' with the actual name of the tweet/text column

# Preprocessing Text: Lowercasing, removing special characters, and links
def clean_text(text):
    text = text.lower()
    text = re.sub(r'http\S+', '', text)  # remove links
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # remove special characters
    return text

df['cleaned_text'] = df['clean_text'].apply(clean_text)

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Function to get sentiment scores
def get_sentiment_vader(text):
    score = sid.polarity_scores(text)
    return score

# Apply sentiment analysis
df['sentiment_scores'] = df['cleaned_text'].apply(get_sentiment_vader)

# Extract compound score and categorize as positive, negative, or neutral
df['compound'] = df['sentiment_scores'].apply(lambda x: x['compound'])
df['sentiment_category'] = df['compound'].apply(lambda score: 'positive' if score >= 0.05 else ('negative' if score <= -0.05 else 'neutral'))


# Display sentiment distribution
print(df['sentiment_category'].value_counts())

# Visualize the sentiment distribution
plt.figure(figsize=(8, 6))
sns.countplot(x='sentiment_category', data=df, palette='coolwarm')
plt.title('Sentiment Distribution')
plt.show()


# Sentiment analysis over time (assuming a 'date_column_name' exists)
df['date_column_name'] = pd.to_datetime(df['category'])  # Replace with actual date column name
df['Month'] = df['date_column_name'].dt.to_period('M')

# Group sentiment by time
sentiment_over_time = df.groupby(['Month', 'sentiment_category']).size().unstack()

# Plot sentiment over time
plt.figure(figsize=(10, 6))
sentiment_over_time.plot(kind='line', marker='o')
plt.title('Sentiment Over Time')
plt.ylabel('Count')
plt.xlabel('Month')
plt.xticks(rotation=45)
plt.show()

# Filter the tweets with negative sentiment
negative_tweets = df[df['sentiment_category'] == 'negative']['cleaned_text'].values

# Join all negative tweets into a single string
negative_text = ' '.join(negative_tweets)

# Generate the Word Cloud for negative sentiment
negative_wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='Reds').generate(negative_text)

# Display the word cloud for negative sentiment
plt.figure(figsize=(10, 6))
plt.imshow(negative_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Negative Sentiment Word Cloud')
plt.show()

# Analyzing specific keywords/topics (e.g., "climate change")
keyword = 'climate change'
df['contains_keyword'] = df['cleaned_text'].apply(lambda x: 1 if keyword in x else 0)
keyword_sentiment = df[df['contains_keyword'] == 1]['sentiment_category'].value_counts()

# Visualize keyword-specific sentiment
plt.figure(figsize=(8, 6))
sns.barplot(x=keyword_sentiment.index, y=keyword_sentiment.values, palette='coolwarm')
plt.title(f'Sentiment for "{keyword}" Mentions')
plt.show()
